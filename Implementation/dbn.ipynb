{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial import distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(arr):\n",
    "    arr = arr.astype(np.float)\n",
    "    arr -= arr.min()\n",
    "    arr /= arr.max()\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16247/1180221328.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  arr = arr.astype(np.float)\n"
     ]
    }
   ],
   "source": [
    "# load MNIST data set\n",
    "mnist = load_digits()\n",
    "X, Y = mnist.data, mnist.target\n",
    "\n",
    "# normalize inputs to 0-1 range\n",
    "X = norm(X)\n",
    "\n",
    "# split into train, validation, and test data sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,       Y,       test_size=200, random_state=0)\n",
    "labels = np.random.binomial(n=1, p=0.5, size=[1000]).reshape(1000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [\"0\", \"1\", \"10\", \"11\", \"12\", \"13\"]\n",
    "data_S = []\n",
    "for index in indices:\n",
    "    data = np.load(f\"../data/data{index}.npy\")\n",
    "    data_S.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 275, 442)\n",
      "(282, 274, 442)\n",
      "(259, 275, 442)\n",
      "(271, 278, 442)\n",
      "(284, 278, 442)\n",
      "(286, 278, 442)\n"
     ]
    }
   ],
   "source": [
    "for data in data_S:\n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_width = 259\n",
    "target_height = 259\n",
    "train = []\n",
    "for data in data_S:\n",
    "    for i in range(442):\n",
    "        data_point = data[:,:,i]\n",
    "        current_height, current_width = data_point.shape\n",
    "\n",
    "        # Calculate the starting points for cropping\n",
    "        start_x = (current_width - target_width) // 2\n",
    "        start_y = (current_height - target_height) // 2\n",
    "\n",
    "        # Crop the image\n",
    "        cropped_data = data_point[start_y:start_y+target_height, start_x:start_x+target_width]\n",
    "\n",
    "\n",
    "        # Scale the 2D array\n",
    "        #scaled_array = (cropped_data- np.min(cropped_data))/(np.max(cropped_data)-np.min(cropped_data))\n",
    "        #scaled_array = norm(cropped_data)\n",
    "\n",
    "        train.append(scaled_array)\n",
    "\n",
    "train = np.array(train)\n",
    "nsamples, nx, ny = train.shape\n",
    "d2_train_dataset = train.reshape((nsamples,nx*ny))\n",
    "d2_train_dataset = norm(d2_train_dataset)\n",
    "train , test =  train_test_split(d2_train_dataset, test_size=200, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2452, 67081)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 67081)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -42548.07, time = 10.74s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -42626.84, time = 12.88s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -36019.48, time = 12.89s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -41847.18, time = 12.72s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -42401.92, time = 12.80s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -36838.59, time = 12.72s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -36201.78, time = 12.76s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -35728.20, time = 13.00s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -35646.21, time = 13.03s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -35397.33, time = 12.81s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -33080.75, time = 12.67s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -32990.95, time = 12.73s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -32232.48, time = 12.91s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -32707.79, time = 12.69s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -36362.17, time = 12.83s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -31253.77, time = 12.68s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -30241.28, time = 12.71s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -36637.50, time = 12.79s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -36333.05, time = 12.66s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -30430.87, time = 12.79s\n",
      "[BernoulliRBM] Iteration 21, pseudo-likelihood = -32734.23, time = 12.73s\n",
      "[BernoulliRBM] Iteration 22, pseudo-likelihood = -32623.73, time = 12.71s\n",
      "[BernoulliRBM] Iteration 23, pseudo-likelihood = -33810.08, time = 12.75s\n",
      "[BernoulliRBM] Iteration 24, pseudo-likelihood = -29511.87, time = 12.70s\n",
      "[BernoulliRBM] Iteration 25, pseudo-likelihood = -30121.58, time = 12.76s\n",
      "[BernoulliRBM] Iteration 26, pseudo-likelihood = -31591.61, time = 12.78s\n",
      "[BernoulliRBM] Iteration 27, pseudo-likelihood = -29410.19, time = 12.73s\n",
      "[BernoulliRBM] Iteration 28, pseudo-likelihood = -35012.68, time = 12.70s\n",
      "[BernoulliRBM] Iteration 29, pseudo-likelihood = -29304.01, time = 12.73s\n",
      "[BernoulliRBM] Iteration 30, pseudo-likelihood = -35057.44, time = 12.82s\n",
      "[BernoulliRBM] Iteration 31, pseudo-likelihood = -29031.80, time = 12.76s\n",
      "[BernoulliRBM] Iteration 32, pseudo-likelihood = -35667.62, time = 12.72s\n",
      "[BernoulliRBM] Iteration 33, pseudo-likelihood = -29144.45, time = 12.68s\n",
      "[BernoulliRBM] Iteration 34, pseudo-likelihood = -35190.51, time = 12.74s\n",
      "[BernoulliRBM] Iteration 35, pseudo-likelihood = -28236.86, time = 12.69s\n",
      "[BernoulliRBM] Iteration 36, pseudo-likelihood = -33162.80, time = 12.74s\n",
      "[BernoulliRBM] Iteration 37, pseudo-likelihood = -29132.25, time = 12.70s\n",
      "[BernoulliRBM] Iteration 38, pseudo-likelihood = -30554.03, time = 12.70s\n",
      "[BernoulliRBM] Iteration 39, pseudo-likelihood = -29035.61, time = 12.70s\n",
      "[BernoulliRBM] Iteration 40, pseudo-likelihood = -29779.49, time = 12.72s\n",
      "[BernoulliRBM] Iteration 41, pseudo-likelihood = -31260.05, time = 12.78s\n",
      "[BernoulliRBM] Iteration 42, pseudo-likelihood = -30539.51, time = 12.75s\n",
      "[BernoulliRBM] Iteration 43, pseudo-likelihood = -32632.97, time = 12.65s\n",
      "[BernoulliRBM] Iteration 44, pseudo-likelihood = -29566.67, time = 12.67s\n",
      "[BernoulliRBM] Iteration 45, pseudo-likelihood = -39027.01, time = 12.66s\n",
      "[BernoulliRBM] Iteration 46, pseudo-likelihood = -39099.12, time = 13.08s\n",
      "[BernoulliRBM] Iteration 47, pseudo-likelihood = -37086.33, time = 13.20s\n",
      "[BernoulliRBM] Iteration 48, pseudo-likelihood = -36912.79, time = 12.89s\n",
      "[BernoulliRBM] Iteration 49, pseudo-likelihood = -37328.31, time = 13.07s\n",
      "[BernoulliRBM] Iteration 50, pseudo-likelihood = -33710.80, time = 13.14s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -342.66, time = 0.11s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -191.49, time = 0.16s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -109.44, time = 0.16s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -72.74, time = 0.16s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -57.19, time = 0.15s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -45.35, time = 0.15s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -40.37, time = 0.16s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -34.68, time = 0.17s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -31.48, time = 0.19s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -29.44, time = 0.15s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -28.13, time = 0.15s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -27.07, time = 0.15s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -25.30, time = 0.15s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -25.04, time = 0.15s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -23.16, time = 0.16s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -23.44, time = 0.16s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -21.80, time = 0.14s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -22.82, time = 0.15s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -21.44, time = 0.16s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -20.67, time = 0.15s\n",
      "[BernoulliRBM] Iteration 21, pseudo-likelihood = -20.62, time = 0.14s\n",
      "[BernoulliRBM] Iteration 22, pseudo-likelihood = -20.30, time = 0.14s\n",
      "[BernoulliRBM] Iteration 23, pseudo-likelihood = -20.78, time = 0.14s\n",
      "[BernoulliRBM] Iteration 24, pseudo-likelihood = -19.66, time = 0.14s\n",
      "[BernoulliRBM] Iteration 25, pseudo-likelihood = -20.04, time = 0.14s\n",
      "[BernoulliRBM] Iteration 26, pseudo-likelihood = -19.72, time = 0.14s\n",
      "[BernoulliRBM] Iteration 27, pseudo-likelihood = -19.26, time = 0.16s\n",
      "[BernoulliRBM] Iteration 28, pseudo-likelihood = -19.61, time = 0.14s\n",
      "[BernoulliRBM] Iteration 29, pseudo-likelihood = -21.01, time = 0.15s\n",
      "[BernoulliRBM] Iteration 30, pseudo-likelihood = -20.85, time = 0.14s\n",
      "[BernoulliRBM] Iteration 31, pseudo-likelihood = -18.81, time = 0.14s\n",
      "[BernoulliRBM] Iteration 32, pseudo-likelihood = -19.92, time = 0.15s\n",
      "[BernoulliRBM] Iteration 33, pseudo-likelihood = -20.38, time = 0.14s\n",
      "[BernoulliRBM] Iteration 34, pseudo-likelihood = -18.61, time = 0.15s\n",
      "[BernoulliRBM] Iteration 35, pseudo-likelihood = -18.48, time = 0.15s\n",
      "[BernoulliRBM] Iteration 36, pseudo-likelihood = -18.78, time = 0.14s\n",
      "[BernoulliRBM] Iteration 37, pseudo-likelihood = -18.85, time = 0.15s\n",
      "[BernoulliRBM] Iteration 38, pseudo-likelihood = -18.26, time = 0.14s\n",
      "[BernoulliRBM] Iteration 39, pseudo-likelihood = -19.44, time = 0.15s\n",
      "[BernoulliRBM] Iteration 40, pseudo-likelihood = -18.10, time = 0.14s\n",
      "[BernoulliRBM] Iteration 41, pseudo-likelihood = -18.61, time = 0.15s\n",
      "[BernoulliRBM] Iteration 42, pseudo-likelihood = -18.72, time = 0.14s\n",
      "[BernoulliRBM] Iteration 43, pseudo-likelihood = -18.49, time = 0.20s\n",
      "[BernoulliRBM] Iteration 44, pseudo-likelihood = -20.30, time = 0.15s\n",
      "[BernoulliRBM] Iteration 45, pseudo-likelihood = -18.30, time = 0.16s\n",
      "[BernoulliRBM] Iteration 46, pseudo-likelihood = -17.20, time = 0.14s\n",
      "[BernoulliRBM] Iteration 47, pseudo-likelihood = -19.41, time = 0.15s\n",
      "[BernoulliRBM] Iteration 48, pseudo-likelihood = -18.36, time = 0.14s\n",
      "[BernoulliRBM] Iteration 49, pseudo-likelihood = -17.81, time = 0.15s\n",
      "[BernoulliRBM] Iteration 50, pseudo-likelihood = -17.17, time = 0.14s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -235.33, time = 0.04s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -203.52, time = 0.07s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -176.10, time = 0.06s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -158.55, time = 0.06s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -147.93, time = 0.08s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -141.88, time = 0.06s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -137.81, time = 0.05s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -135.75, time = 0.06s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -134.20, time = 0.06s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -133.20, time = 0.06s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -132.47, time = 0.06s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -132.75, time = 0.05s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -132.32, time = 0.06s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -132.17, time = 0.06s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -131.98, time = 0.06s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -131.78, time = 0.06s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -131.88, time = 0.06s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -131.76, time = 0.06s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -131.70, time = 0.05s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -131.41, time = 0.06s\n",
      "[BernoulliRBM] Iteration 21, pseudo-likelihood = -131.86, time = 0.06s\n",
      "[BernoulliRBM] Iteration 22, pseudo-likelihood = -131.56, time = 0.06s\n",
      "[BernoulliRBM] Iteration 23, pseudo-likelihood = -131.68, time = 0.06s\n",
      "[BernoulliRBM] Iteration 24, pseudo-likelihood = -131.51, time = 0.06s\n",
      "[BernoulliRBM] Iteration 25, pseudo-likelihood = -131.75, time = 0.06s\n",
      "[BernoulliRBM] Iteration 26, pseudo-likelihood = -131.82, time = 0.06s\n",
      "[BernoulliRBM] Iteration 27, pseudo-likelihood = -131.44, time = 0.06s\n",
      "[BernoulliRBM] Iteration 28, pseudo-likelihood = -131.81, time = 0.05s\n",
      "[BernoulliRBM] Iteration 29, pseudo-likelihood = -131.65, time = 0.06s\n",
      "[BernoulliRBM] Iteration 30, pseudo-likelihood = -132.23, time = 0.06s\n",
      "[BernoulliRBM] Iteration 31, pseudo-likelihood = -131.41, time = 0.05s\n",
      "[BernoulliRBM] Iteration 32, pseudo-likelihood = -131.81, time = 0.06s\n",
      "[BernoulliRBM] Iteration 33, pseudo-likelihood = -132.06, time = 0.06s\n",
      "[BernoulliRBM] Iteration 34, pseudo-likelihood = -131.66, time = 0.06s\n",
      "[BernoulliRBM] Iteration 35, pseudo-likelihood = -131.57, time = 0.06s\n",
      "[BernoulliRBM] Iteration 36, pseudo-likelihood = -131.58, time = 0.06s\n",
      "[BernoulliRBM] Iteration 37, pseudo-likelihood = -131.55, time = 0.07s\n",
      "[BernoulliRBM] Iteration 38, pseudo-likelihood = -131.87, time = 0.06s\n",
      "[BernoulliRBM] Iteration 39, pseudo-likelihood = -131.71, time = 0.06s\n",
      "[BernoulliRBM] Iteration 40, pseudo-likelihood = -132.06, time = 0.05s\n",
      "[BernoulliRBM] Iteration 41, pseudo-likelihood = -132.05, time = 0.06s\n",
      "[BernoulliRBM] Iteration 42, pseudo-likelihood = -131.94, time = 0.06s\n",
      "[BernoulliRBM] Iteration 43, pseudo-likelihood = -131.78, time = 0.06s\n",
      "[BernoulliRBM] Iteration 44, pseudo-likelihood = -131.42, time = 0.06s\n",
      "[BernoulliRBM] Iteration 45, pseudo-likelihood = -131.69, time = 0.06s\n",
      "[BernoulliRBM] Iteration 46, pseudo-likelihood = -131.70, time = 0.06s\n",
      "[BernoulliRBM] Iteration 47, pseudo-likelihood = -131.66, time = 0.06s\n",
      "[BernoulliRBM] Iteration 48, pseudo-likelihood = -131.65, time = 0.05s\n",
      "[BernoulliRBM] Iteration 49, pseudo-likelihood = -131.75, time = 0.06s\n",
      "[BernoulliRBM] Iteration 50, pseudo-likelihood = -131.52, time = 0.06s\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -118.25, time = 0.02s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -103.67, time = 0.04s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -88.42, time = 0.04s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -75.02, time = 0.03s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -65.20, time = 0.04s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -58.33, time = 0.03s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -53.41, time = 0.03s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -49.91, time = 0.04s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -47.34, time = 0.03s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -45.54, time = 0.03s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -43.82, time = 0.04s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -43.16, time = 0.04s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -42.36, time = 0.03s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -41.55, time = 0.03s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -41.11, time = 0.04s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -40.79, time = 0.03s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -40.49, time = 0.04s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -40.33, time = 0.03s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -40.07, time = 0.03s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -39.89, time = 0.03s\n",
      "[BernoulliRBM] Iteration 21, pseudo-likelihood = -39.42, time = 0.03s\n",
      "[BernoulliRBM] Iteration 22, pseudo-likelihood = -39.58, time = 0.03s\n",
      "[BernoulliRBM] Iteration 23, pseudo-likelihood = -39.20, time = 0.04s\n",
      "[BernoulliRBM] Iteration 24, pseudo-likelihood = -39.31, time = 0.03s\n",
      "[BernoulliRBM] Iteration 25, pseudo-likelihood = -39.36, time = 0.03s\n",
      "[BernoulliRBM] Iteration 26, pseudo-likelihood = -39.29, time = 0.03s\n",
      "[BernoulliRBM] Iteration 27, pseudo-likelihood = -39.39, time = 0.03s\n",
      "[BernoulliRBM] Iteration 28, pseudo-likelihood = -39.31, time = 0.04s\n",
      "[BernoulliRBM] Iteration 29, pseudo-likelihood = -38.94, time = 0.04s\n",
      "[BernoulliRBM] Iteration 30, pseudo-likelihood = -39.12, time = 0.03s\n",
      "[BernoulliRBM] Iteration 31, pseudo-likelihood = -38.99, time = 0.04s\n",
      "[BernoulliRBM] Iteration 32, pseudo-likelihood = -39.13, time = 0.03s\n",
      "[BernoulliRBM] Iteration 33, pseudo-likelihood = -39.13, time = 0.04s\n",
      "[BernoulliRBM] Iteration 34, pseudo-likelihood = -38.96, time = 0.03s\n",
      "[BernoulliRBM] Iteration 35, pseudo-likelihood = -39.02, time = 0.04s\n",
      "[BernoulliRBM] Iteration 36, pseudo-likelihood = -39.02, time = 0.03s\n",
      "[BernoulliRBM] Iteration 37, pseudo-likelihood = -39.18, time = 0.03s\n",
      "[BernoulliRBM] Iteration 38, pseudo-likelihood = -39.30, time = 0.03s\n",
      "[BernoulliRBM] Iteration 39, pseudo-likelihood = -39.05, time = 0.03s\n",
      "[BernoulliRBM] Iteration 40, pseudo-likelihood = -38.91, time = 0.03s\n",
      "[BernoulliRBM] Iteration 41, pseudo-likelihood = -38.97, time = 0.03s\n",
      "[BernoulliRBM] Iteration 42, pseudo-likelihood = -39.02, time = 0.04s\n",
      "[BernoulliRBM] Iteration 43, pseudo-likelihood = -39.09, time = 0.04s\n",
      "[BernoulliRBM] Iteration 44, pseudo-likelihood = -38.96, time = 0.03s\n",
      "[BernoulliRBM] Iteration 45, pseudo-likelihood = -39.15, time = 0.03s\n",
      "[BernoulliRBM] Iteration 46, pseudo-likelihood = -39.18, time = 0.03s\n",
      "[BernoulliRBM] Iteration 47, pseudo-likelihood = -39.09, time = 0.03s\n",
      "[BernoulliRBM] Iteration 48, pseudo-likelihood = -39.19, time = 0.04s\n",
      "[BernoulliRBM] Iteration 49, pseudo-likelihood = -39.12, time = 0.03s\n",
      "[BernoulliRBM] Iteration 50, pseudo-likelihood = -39.20, time = 0.03s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;rbm1&#x27;,\n",
       "                 BernoulliRBM(batch_size=256, learning_rate=0.001,\n",
       "                              n_components=750, n_iter=50, verbose=2)),\n",
       "                (&#x27;rbm2&#x27;,\n",
       "                 BernoulliRBM(batch_size=256, learning_rate=0.001,\n",
       "                              n_components=375, n_iter=50, verbose=2)),\n",
       "                (&#x27;rbm3&#x27;,\n",
       "                 BernoulliRBM(batch_size=256, learning_rate=0.001,\n",
       "                              n_components=187, n_iter=50, verbose=2)),\n",
       "                (&#x27;rbm4&#x27;,\n",
       "                 BernoulliRBM(batch_size=256, learning_rate=0.001,\n",
       "                              n_components=125, n_iter=50, verbose=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;rbm1&#x27;,\n",
       "                 BernoulliRBM(batch_size=256, learning_rate=0.001,\n",
       "                              n_components=750, n_iter=50, verbose=2)),\n",
       "                (&#x27;rbm2&#x27;,\n",
       "                 BernoulliRBM(batch_size=256, learning_rate=0.001,\n",
       "                              n_components=375, n_iter=50, verbose=2)),\n",
       "                (&#x27;rbm3&#x27;,\n",
       "                 BernoulliRBM(batch_size=256, learning_rate=0.001,\n",
       "                              n_components=187, n_iter=50, verbose=2)),\n",
       "                (&#x27;rbm4&#x27;,\n",
       "                 BernoulliRBM(batch_size=256, learning_rate=0.001,\n",
       "                              n_components=125, n_iter=50, verbose=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliRBM</label><div class=\"sk-toggleable__content\"><pre>BernoulliRBM(batch_size=256, learning_rate=0.001, n_components=750, n_iter=50,\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliRBM</label><div class=\"sk-toggleable__content\"><pre>BernoulliRBM(batch_size=256, learning_rate=0.001, n_components=375, n_iter=50,\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliRBM</label><div class=\"sk-toggleable__content\"><pre>BernoulliRBM(batch_size=256, learning_rate=0.001, n_components=187, n_iter=50,\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliRBM</label><div class=\"sk-toggleable__content\"><pre>BernoulliRBM(batch_size=256, learning_rate=0.001, n_components=125, n_iter=50,\n",
       "             verbose=1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('rbm1',\n",
       "                 BernoulliRBM(batch_size=256, learning_rate=0.001,\n",
       "                              n_components=750, n_iter=50, verbose=2)),\n",
       "                ('rbm2',\n",
       "                 BernoulliRBM(batch_size=256, learning_rate=0.001,\n",
       "                              n_components=375, n_iter=50, verbose=2)),\n",
       "                ('rbm3',\n",
       "                 BernoulliRBM(batch_size=256, learning_rate=0.001,\n",
       "                              n_components=187, n_iter=50, verbose=2)),\n",
       "                ('rbm4',\n",
       "                 BernoulliRBM(batch_size=256, learning_rate=0.001,\n",
       "                              n_components=125, n_iter=50, verbose=1))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# set hyperparameters\n",
    "\n",
    "learning_rate = 0.001\n",
    "total_units   =  750 \n",
    "total_epochs  =   50 \n",
    "batch_size    =  256 \n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# construct models\n",
    "\n",
    "# RBM\n",
    "rbm1 = BernoulliRBM(n_components=total_units, learning_rate=learning_rate, batch_size=batch_size, n_iter=total_epochs, verbose=2)\n",
    "rbm2 = BernoulliRBM(n_components=int(total_units/2), learning_rate=learning_rate, batch_size=batch_size, n_iter=total_epochs, verbose=2)\n",
    "rbm3 = BernoulliRBM(n_components=int(total_units/4), learning_rate=learning_rate, batch_size=batch_size, n_iter=total_epochs, verbose=2)\n",
    "rbm4 = BernoulliRBM(n_components=int(total_units/6), learning_rate=learning_rate, batch_size=batch_size, n_iter=total_epochs, verbose=1)\n",
    "\n",
    "\n",
    "models = []                       \n",
    "model = Pipeline(steps=[('rbm1', clone(rbm1)), ('rbm2', clone(rbm2)),('rbm3', clone(rbm3)),('rbm4', clone(rbm4))])  # RBM stack / DBN\n",
    "# --------------------------------------------------------------------------------\n",
    "# train and evaluate models\n",
    "\n",
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_activation(x):\n",
    "    \"\"\"\n",
    "    Numerically stable sigmoid function with clipping.\n",
    "    \n",
    "    :param x: Input array.\n",
    "    :return: Sigmoid of x.\n",
    "    \"\"\"\n",
    "    # Clip x to avoid overflow in exp\n",
    "    clipped_x = np.clip(x, -500, 500)\n",
    "\n",
    "    return np.where(clipped_x >= 0, \n",
    "                    1 / (1 + np.exp(-clipped_x)), \n",
    "                    np.exp(clipped_x) / (1 + np.exp(clipped_x)))\n",
    "\n",
    "\n",
    "def reconstruct_visible(rbm, hidden):\n",
    "    \"\"\"\n",
    "    Reconstruct the visible units from the hidden units in an RBM.\n",
    "\n",
    "    :param rbm: Trained instance of BernoulliRBM.\n",
    "    :param hidden: Array of hidden units.\n",
    "    :return: Reconstructed visible units.\n",
    "    \"\"\"\n",
    "    # Compute the activation of the visible units\n",
    "    v_activation = np.dot(hidden, rbm.components_) + rbm.intercept_visible_\n",
    "\n",
    "    # Compute the probability of the visible units given the hidden units\n",
    "    v_prob = sigmoid_activation(v_activation)\n",
    "\n",
    "    # Sample from these probabilities to get the binary visible units\n",
    "    # For BernoulliRBM, this step can be binary sampling or directly using probabilities\n",
    "    v_reconstructed = np.random.binomial(1, v_prob)\n",
    "\n",
    "    return v_reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_features = model.transform(test)\n",
    "# Initialize the reconstructed data with the hidden features\n",
    "reconstructed_data = hidden_features\n",
    "\n",
    "# Reconstruct the data from the top RBM to the bottom\n",
    "for rbm in reversed(model.steps):\n",
    "    reconstructed_data = reconstruct_visible(rbm[1], reconstructed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the original and reconstructed data if they are in 2D or 3D\n",
    "original_data_flat = test.flatten()\n",
    "reconstructed_data_flat = reconstructed_data.flatten()\n",
    "\n",
    "# Compute the reconstruction error for each sample\n",
    "reconstruction_errors = mean_squared_error(original_data_flat, reconstructed_data_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23991734846684787"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Outlier Predictions (True Positives): 0\n",
      "Correct Non-Outlier Predictions (True Negatives): 200\n",
      "Incorrect Outlier Predictions (False Positives): 0\n",
      "Incorrect Non-Outlier Predictions (False Negatives): 0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "transformed_features = model.transform(test)\n",
    "\n",
    "# Calculate the centroid of the transformed features\n",
    "centroid = np.mean(transformed_features, axis=0)\n",
    "\n",
    "# Compute distances of each sample from the centroid\n",
    "distances = distance.cdist(transformed_features, [centroid], 'euclidean').flatten()\n",
    "\n",
    "# Determine a threshold for considering a point as an outlier\n",
    "threshold = np.percentile(distances, 95)  # for example, top 5% as outliers\n",
    "\n",
    "# Flag points as outliers\n",
    "outliers = distances > threshold\n",
    "\n",
    "truth = np.zeros(200)\n",
    "\n",
    "def evaluate_outlier_predictions(predicted_outliers, true_outliers):\n",
    "    TP = np.sum((predicted_outliers == 1) & (true_outliers == 1))  # True Positives\n",
    "    TN = np.sum((predicted_outliers == 0) & (true_outliers == 0))  # True Negatives\n",
    "    FP = np.sum((predicted_outliers == 1) & (true_outliers == 0))  # False Positives\n",
    "    FN = np.sum((predicted_outliers == 0) & (true_outliers == 1))  # False Negatives\n",
    "\n",
    "    print(f\"Correct Outlier Predictions (True Positives): {TP}\")\n",
    "    print(f\"Correct Non-Outlier Predictions (True Negatives): {TN}\")\n",
    "    print(f\"Incorrect Outlier Predictions (False Positives): {FP}\")\n",
    "    print(f\"Incorrect Non-Outlier Predictions (False Negatives): {FN}\")\n",
    "\n",
    "# Evaluate your model's performance\n",
    "evaluate_outlier_predictions(outliers, truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# set hyperparameters\n",
    "\n",
    "total_units   =  259 \n",
    "total_epochs  =   50 \n",
    "batch_size    =  1 \n",
    "\n",
    "\n",
    "# RBM\n",
    "rbm1 = BernoulliRBM(n_components=total_units, learning_rate=learning_rate, batch_size=batch_size, n_iter=total_epochs, verbose=1)\n",
    "rbm2 = BernoulliRBM(n_components=int(total_units/2), learning_rate=learning_rate, batch_size=batch_size, n_iter=total_epochs, verbose=1)\n",
    "rbm3 = BernoulliRBM(n_components=int(total_units/4), learning_rate=learning_rate, batch_size=batch_size, n_iter=total_epochs, verbose=1)\n",
    "\n",
    "\n",
    "models = []                       \n",
    "model = Pipeline(steps=[('rbm1', clone(rbm1)), ('rbm2', clone(rbm2)),('rbm3', clone(rbm3))])  # RBM stack / DBN\n",
    "# --------------------------------------------------------------------------------\n",
    "# train and evaluate models\n",
    "\n",
    "model.fit(X_train)\n",
    "\n",
    "def transform_through_dbn(data, rbms):\n",
    "    for rbm in rbms:\n",
    "        data = rbm.transform(data)\n",
    "    return data\n",
    "    \n",
    "# Extract features using DBN\n",
    "dbn_features = transform_through_dbn(X_train, model)  # Replace with your DBN layers\n",
    "\n",
    "# Initialize and train the classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(dbn_features, Y_train)\n",
    "\n",
    "predictions = classifier.predict(transform_through_dbn(X_train, model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(model, 'model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
